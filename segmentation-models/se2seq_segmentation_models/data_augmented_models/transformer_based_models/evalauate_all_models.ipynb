{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3122f39-88ce-4aa6-8eef-5225102dfbec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 19:09:50.922607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 19:09:51.714171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from seq2seq_train import Seq2SeqTrainer\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from torchmetrics.text import SacreBLEUScore\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f86ca7b-dcdc-47a1-9871-ce2450e064d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_model_comparison(config_paths):\n",
    "    # Initialize lists to store results\n",
    "    results = []\n",
    "    \n",
    "    for config_path in config_paths:\n",
    "        print(f\"Attempting to load from: {config_path}\")\n",
    "        \n",
    "        with open(config_path, \"r\") as f:\n",
    "            loaded_config = json.load(f)\n",
    "        \n",
    "        # Initialize trainer with new dataset size but keeping optimized parameters\n",
    "        trainer = Seq2SeqTrainer(loaded_config)\n",
    "        trainer.load_pretrained_model()\n",
    "        \n",
    "        # Get predictions and compute metrics\n",
    "#         predicted, targeted = trainer.generate_predictions()  //  uncomment to segment for the first time\n",
    "\n",
    "        predicted, targeted, sources = trainer.get_predictions_from_file()\n",
    "\n",
    "        \n",
    "        position_scores = trainer.eval_morph_segments_position(predicted, targeted)\n",
    "        bleu_scores = trainer.eval_bleu_segment(predicted, targeted)\n",
    "        chrf_score = trainer.eval_chrF_segment(predicted, targeted)\n",
    "        sacre_bleu = trainer.eval_sacrebleu_segment(predicted, targeted)\n",
    "\n",
    "        # Save individual model results\n",
    "        trainer.save_evaluation_results(loaded_config[\"file_path\"], position_scores, bleu_scores, chrf_score, sacre_bleu)\n",
    "        \n",
    "        # Collect results for comparison\n",
    "        result = {\n",
    "            'model_name': loaded_config.get('model_name', loaded_config[\"file_path\"].split(\"/\")[-1]),\n",
    "            'position_precision': position_scores['precision'],\n",
    "            'position_recall': position_scores['recall'],\n",
    "            'position_f1': position_scores['f1'],\n",
    "            'bleu': bleu_scores['equal'],\n",
    "            'chrf': chrf_score,\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Position Scores: Precision={result['position_precision']:.3f}, Recall={result['position_recall']:.3f}, F1={result['position_f1']:.3f}\")\n",
    "        print(f\"BLEU Score: {result['bleu']:.4f}\")\n",
    "        print(f\"chrF Score: {result['chrf']:.4f}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    comparison_file = \"model_comparison_results_unaugmented.csv\"\n",
    "    \n",
    "    # If file exists, append without headers\n",
    "    if os.path.exists(comparison_file):\n",
    "        df.to_csv(comparison_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(comparison_file, index=False)\n",
    "    \n",
    "    print(f\"\\nComparison results saved to: {comparison_file}\")\n",
    "    \n",
    "    # Create a formatted markdown table for easy viewing\n",
    "    markdown_table = \"# Model Comparison Results\\n\\n\"\n",
    "    markdown_table += df.to_markdown(index=False)\n",
    "    \n",
    "    with open(\"model_comparison_results_unaugmented.md\", \"w\") as f:\n",
    "        f.write(markdown_table)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5545e720-f722-47ec-9049-15d3633ae193",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load from: unaugmented_transformer_models/segmenter_one/model_config.json\n",
      "Using device: cuda\n",
      "Device name: NVIDIA RTX A6000\n",
      "Device memory: 47.535888671875 GB\n",
      "Original shape: (367178, 4)\n",
      "Final shape: (100000, 4)\n",
      "The config file has been saved on unaugmented_transformer_models/segmenter_one\n",
      "Tokenizer path: unaugmented_transformer_models/segmenter_one/tokenizers/tokenizers_tokens.json\n",
      "Loading existing tokenizer from unaugmented_transformer_models/segmenter_one/tokenizers/tokenizers_tokens.json\n",
      "Tokenizer path: unaugmented_transformer_models/segmenter_one/tokenizers/tokenizers_segmenter_one.json\n",
      "Loading existing tokenizer from unaugmented_transformer_models/segmenter_one/tokenizers/tokenizers_segmenter_one.json\n",
      "the dataset length: 100000\n",
      "Max length of source sentence: 30\n",
      "Max length of target sentence: 41\n",
      "Loaded best model from epoch 6\n",
      "Model configuration:\n",
      "- d_model: 1024\n",
      "- num_layers: 3\n",
      "- num_heads: 4\n",
      "- d_ff: 1024\n",
      "- dropout: 0.1129068748094076\n",
      "- label_smoothing: 0.03986699895923636\n",
      "- max_grad_norm: 1.1843786467139337\n",
      "- lr: 0.00018609171407151109\n",
      "Loaded best model from epoch 6\n",
      "Model configuration:\n",
      "- d_model: 1024\n",
      "- num_layers: 3\n",
      "- num_heads: 4\n",
      "- d_ff: 1024\n",
      "- dropout: 0.1129068748094076\n",
      "- label_smoothing: 0.03986699895923636\n",
      "- max_grad_norm: 1.1843786467139337\n",
      "- lr: 0.00018609171407151109\n",
      "Reading predictions from: unaugmented_transformer_models/segmenter_one/predictions/predictions_20250316_113448.csv\n",
      "Successfully loaded 7628 predictions\n",
      "\n",
      "Example predictions:\n",
      "\n",
      "Example 1:\n",
      "Source: iyokhuthaza\n",
      "Target: i-yo-khuthaz-a\n",
      "Predicted: i-yo-khuthaz-a\n",
      "\n",
      "Example 2:\n",
      "Source: abangazinaki\n",
      "Target: aba-nga-zi-nak-i\n",
      "Predicted: a-ba-nga-zi-nak-i\n",
      "\n",
      "Example 3:\n",
      "Source: sivikele\n",
      "Target: si-vikel-e\n",
      "Predicted: si-vikel-e\n",
      "Original pairs: 7628\n",
      "Valid pairs after filtering: 7628\n",
      "Filtered out 0 pairs\n",
      "Original pairs: 7628\n",
      "Valid pairs after filtering: 7628\n",
      "Filtered out 0 pairs\n",
      "The evaluation results were successfully saved to:\n",
      "- Text format: unaugmented_transformer_models/segmenter_one/evaluation_results.txt\n",
      "Model: segmenter_one\n",
      "Position Scores: Precision=0.832, Recall=0.848, F1=0.840\n",
      "BLEU Score: 0.8426\n",
      "chrF Score: 0.9127\n",
      "Attempting to load from: unaugmented_transformer_models/segmenter_two/model_config.json\n",
      "Using device: cuda\n",
      "Device name: NVIDIA RTX A6000\n",
      "Device memory: 47.535888671875 GB\n",
      "Original shape: (367178, 4)\n",
      "Final shape: (100000, 4)\n",
      "The config file has been saved on unaugmented_transformer_models/segmenter_two\n",
      "Tokenizer path: unaugmented_transformer_models/segmenter_two/tokenizers/tokenizers_tokens.json\n",
      "Loading existing tokenizer from unaugmented_transformer_models/segmenter_two/tokenizers/tokenizers_tokens.json\n",
      "Tokenizer path: unaugmented_transformer_models/segmenter_two/tokenizers/tokenizers_segmenter_two.json\n",
      "Loading existing tokenizer from unaugmented_transformer_models/segmenter_two/tokenizers/tokenizers_segmenter_two.json\n",
      "the dataset length: 100000\n",
      "Max length of source sentence: 30\n",
      "Max length of target sentence: 39\n",
      "Loaded best model from epoch 24\n",
      "Model configuration:\n",
      "- d_model: 1024\n",
      "- num_layers: 3\n",
      "- num_heads: 4\n",
      "- d_ff: 1024\n",
      "- dropout: 0.1031247539135942\n",
      "- label_smoothing: 0.023059042902177463\n",
      "- max_grad_norm: 1.483162866941314\n",
      "- lr: 2.6890024280246086e-05\n",
      "Loaded best model from epoch 24\n",
      "Model configuration:\n",
      "- d_model: 1024\n",
      "- num_layers: 3\n",
      "- num_heads: 4\n",
      "- d_ff: 1024\n",
      "- dropout: 0.1031247539135942\n",
      "- label_smoothing: 0.023059042902177463\n",
      "- max_grad_norm: 1.483162866941314\n",
      "- lr: 2.6890024280246086e-05\n",
      "Reading predictions from: unaugmented_transformer_models/segmenter_two/predictions/predictions_20250316_114238.csv\n",
      "Successfully loaded 7628 predictions\n",
      "\n",
      "Example predictions:\n",
      "\n",
      "Example 1:\n",
      "Source: iyokhuthaza\n",
      "Target: i-yo-khuthaz-a\n",
      "Predicted: i-yo-khuthaz-a\n",
      "\n",
      "Example 2:\n",
      "Source: abangazinaki\n",
      "Target: aba-nga-zi-nak-i\n",
      "Predicted: aba-nga-zi-nak-i\n",
      "\n",
      "Example 3:\n",
      "Source: sivikele\n",
      "Target: si-vikel-e\n",
      "Predicted: si-vikel-e\n",
      "Original pairs: 7628\n",
      "Valid pairs after filtering: 7628\n",
      "Filtered out 0 pairs\n",
      "Original pairs: 7628\n",
      "Valid pairs after filtering: 7628\n",
      "Filtered out 0 pairs\n",
      "The evaluation results were successfully saved to:\n",
      "- Text format: unaugmented_transformer_models/segmenter_two/evaluation_results.txt\n",
      "Model: segmenter_two\n",
      "Position Scores: Precision=0.907, Recall=0.917, F1=0.912\n",
      "BLEU Score: 0.9160\n",
      "chrF Score: 0.9531\n",
      "Attempting to load from: unaugmented_transformer_models/segmenter_three/model_config.json\n",
      "Using device: cuda\n",
      "Device name: NVIDIA RTX A6000\n",
      "Device memory: 47.535888671875 GB\n",
      "Original shape: (367178, 4)\n",
      "Final shape: (100000, 4)\n",
      "The config file has been saved on unaugmented_transformer_models/segmenter_three\n",
      "Tokenizer path: unaugmented_transformer_models/segmenter_three/tokenizers/tokenizers_tokens.json\n",
      "Loading existing tokenizer from unaugmented_transformer_models/segmenter_three/tokenizers/tokenizers_tokens.json\n",
      "Tokenizer path: unaugmented_transformer_models/segmenter_three/tokenizers/tokenizers_segmenter_three.json\n",
      "Loading existing tokenizer from unaugmented_transformer_models/segmenter_three/tokenizers/tokenizers_segmenter_three.json\n",
      "the dataset length: 100000\n",
      "Max length of source sentence: 30\n",
      "Max length of target sentence: 36\n",
      "Loaded best model from epoch 8\n",
      "Model configuration:\n",
      "- d_model: 256\n",
      "- num_layers: 4\n",
      "- num_heads: 4\n",
      "- d_ff: 2048\n",
      "- dropout: 0.22297512658672303\n",
      "- label_smoothing: 0.02106466014212225\n",
      "- max_grad_norm: 1.0428447558315492\n",
      "- lr: 0.0008865029094763138\n",
      "Loaded best model from epoch 8\n",
      "Model configuration:\n",
      "- d_model: 256\n",
      "- num_layers: 4\n",
      "- num_heads: 4\n",
      "- d_ff: 2048\n",
      "- dropout: 0.22297512658672303\n",
      "- label_smoothing: 0.02106466014212225\n",
      "- max_grad_norm: 1.0428447558315492\n",
      "- lr: 0.0008865029094763138\n",
      "Reading predictions from: unaugmented_transformer_models/segmenter_three/predictions/predictions_20250316_115155.csv\n",
      "Successfully loaded 7628 predictions\n",
      "\n",
      "Example predictions:\n",
      "\n",
      "Example 1:\n",
      "Source: iyokhuthaza\n",
      "Target: iyo-khuthaz-a\n",
      "Predicted: iyo-khuthaz-a\n",
      "\n",
      "Example 2:\n",
      "Source: abangazinaki\n",
      "Target: abangazi-nak-i\n",
      "Predicted: abangazinak-i\n",
      "\n",
      "Example 3:\n",
      "Source: sivikele\n",
      "Target: si-vikel-e\n",
      "Predicted: si-vikel-e\n",
      "Original pairs: 7628\n",
      "Valid pairs after filtering: 7628\n",
      "Filtered out 0 pairs\n",
      "Original pairs: 7628\n",
      "Valid pairs after filtering: 7628\n",
      "Filtered out 0 pairs\n",
      "The evaluation results were successfully saved to:\n",
      "- Text format: unaugmented_transformer_models/segmenter_three/evaluation_results.txt\n",
      "Model: segmenter_three\n",
      "Position Scores: Precision=0.816, Recall=0.819, F1=0.817\n",
      "BLEU Score: 0.8206\n",
      "chrF Score: 0.9058\n",
      "\n",
      "Comparison results saved to: model_comparison_results_unaugmented.csv\n",
      "\n",
      "Comparison Summary:\n",
      "        model_name  position_precision  position_recall  position_f1  \\\n",
      "0    segmenter_one            0.831760         0.848458     0.840026   \n",
      "1    segmenter_two            0.906824         0.917290     0.912027   \n",
      "2  segmenter_three            0.816179         0.818669     0.817422   \n",
      "\n",
      "       bleu      chrf            timestamp  \n",
      "0  0.842647  0.912698  2025-03-24 19:13:36  \n",
      "1  0.915954  0.953100  2025-03-24 19:13:43  \n",
      "2  0.820610  0.905788  2025-03-24 19:13:49  \n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    config_paths = [\n",
    "        \"unaugmented_transformer_models/segmenter_one/model_config.json\",\n",
    "        \"unaugmented_transformer_models/segmenter_two/model_config.json\",\n",
    "        \"unaugmented_transformer_models/segmenter_three/model_config.json\"\n",
    "    ]\n",
    "    comparison_df = save_model_comparison(config_paths)\n",
    "    print(\"\\nComparison Summary:\")\n",
    "    print(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
