{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3122f39-88ce-4aa6-8eef-5225102dfbec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 18:47:53.776794: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 18:47:54.551887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from seq2seq_train import Seq2SeqTrainer\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from torchmetrics.text import SacreBLEUScore\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f86ca7b-dcdc-47a1-9871-ce2450e064d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_model_comparison(config_paths):\n",
    "    # Initialize lists to store results\n",
    "    results = []\n",
    "    \n",
    "    for config_path in config_paths:\n",
    "        print(f\"Attempting to load from: {config_path}\")\n",
    "        \n",
    "        with open(config_path, \"r\") as f:\n",
    "            loaded_config = json.load(f)\n",
    "        \n",
    "        # Initialize trainer with new dataset size but keeping optimized parameters\n",
    "        trainer = Seq2SeqTrainer(loaded_config)\n",
    "        trainer.load_pretrained_model()\n",
    "        \n",
    "        # Get predictions and compute metrics\n",
    "#         predicted, targeted = trainer.generate_predictions()  //  uncomment to segment for the first time\n",
    "\n",
    "        predicted, targeted, sources = trainer.get_predictions_from_file()\n",
    "\n",
    "        \n",
    "        position_scores = trainer.eval_morph_segments_position(predicted, targeted)\n",
    "        bleu_scores = trainer.eval_bleu_segment(predicted, targeted)\n",
    "        chrf_score = trainer.eval_chrF_segment(predicted, targeted)\n",
    "        sacre_bleu = trainer.eval_sacrebleu_segment(predicted, targeted)\n",
    "\n",
    "        # Save individual model results\n",
    "        trainer.save_evaluation_results(loaded_config[\"file_path\"], position_scores, bleu_scores, chrf_score, sacre_bleu)\n",
    "        \n",
    "        # Collect results for comparison\n",
    "        result = {\n",
    "            'model_name': loaded_config.get('model_name', loaded_config[\"file_path\"].split(\"/\")[-1]),\n",
    "            'position_precision': position_scores['precision'],\n",
    "            'position_recall': position_scores['recall'],\n",
    "            'position_f1': position_scores['f1'],\n",
    "            'bleu': bleu_scores['equal'],\n",
    "            'chrf': chrf_score,\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"Model: {result['model_name']}\")\n",
    "        print(f\"Position Scores: Precision={result['position_precision']:.3f}, Recall={result['position_recall']:.3f}, F1={result['position_f1']:.3f}\")\n",
    "        print(f\"BLEU Score: {result['bleu']:.4f}\")\n",
    "        print(f\"chrF Score: {result['chrf']:.4f}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    comparison_file = \"model_comparison_results_augmented.csv\"\n",
    "    \n",
    "    # If file exists, append without headers\n",
    "    if os.path.exists(comparison_file):\n",
    "        df.to_csv(comparison_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(comparison_file, index=False)\n",
    "    \n",
    "    print(f\"\\nComparison results saved to: {comparison_file}\")\n",
    "    \n",
    "    # Create a formatted markdown table for easy viewing\n",
    "    markdown_table = \"# Model Comparison Results\\n\\n\"\n",
    "    markdown_table += df.to_markdown(index=False)\n",
    "    \n",
    "    with open(\"model_comparison_results_augmented.md\", \"w\") as f:\n",
    "        f.write(markdown_table)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5545e720-f722-47ec-9049-15d3633ae193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load from: segmenter_one/model_config.json\n",
      "Using device: cuda\n",
      "Device name: NVIDIA RTX A6000\n",
      "Device memory: 47.535888671875 GB\n",
      "Original shape: (367178, 4)\n",
      "Final shape: (200000, 4)\n",
      "The config file has been saved on segmenter_one\n",
      "Tokenizer path: segmenter_one/tokenizers/tokenizers_tokens.json\n",
      "Loading existing tokenizer from segmenter_one/tokenizers/tokenizers_tokens.json\n",
      "Tokenizer path: segmenter_one/tokenizers/tokenizers_segmenter_one.json\n",
      "Loading existing tokenizer from segmenter_one/tokenizers/tokenizers_segmenter_one.json\n",
      "the dataset length: 200000\n",
      "Max length of source sentence: 30\n",
      "Max length of target sentence: 41\n",
      "Loaded best model from epoch 20\n",
      "Model configuration:\n",
      "- d_model: 128\n",
      "- num_layers: 3\n",
      "- num_heads: 16\n",
      "- d_ff: 1024\n",
      "- dropout: 0.18953066758095358\n",
      "- label_smoothing: 0.000949605759638339\n",
      "- max_grad_norm: 0.5246939924778026\n",
      "- lr: 0.0004800819901770108\n",
      "Loaded best model from epoch 20\n",
      "Model configuration:\n",
      "- d_model: 128\n",
      "- num_layers: 3\n",
      "- num_heads: 16\n",
      "- d_ff: 1024\n",
      "- dropout: 0.18953066758095358\n",
      "- label_smoothing: 0.000949605759638339\n",
      "- max_grad_norm: 0.5246939924778026\n",
      "- lr: 0.0004800819901770108\n",
      "Reading predictions from: segmenter_one/predictions/predictions_20250106_130846.csv\n",
      "Successfully loaded 20000 predictions\n",
      "\n",
      "Example predictions:\n",
      "\n",
      "Example 1:\n",
      "Source: anizukuza\n",
      "Target: a-ni-zuku-z-a\n",
      "Predicted: a-ni-zuku-z-a\n",
      "\n",
      "Example 2:\n",
      "Source: sezinkantolo\n",
      "Target: se-zin-kantolo\n",
      "Predicted: se-zin-kantolo\n",
      "\n",
      "Example 3:\n",
      "Source: ezingathenganga\n",
      "Target: ezi-nga-theng-anga\n",
      "Predicted: ezi-nga-theng-anga\n",
      "Original pairs: 20000\n",
      "Valid pairs after filtering: 20000\n",
      "Filtered out 0 pairs\n",
      "Original pairs: 20000\n",
      "Valid pairs after filtering: 20000\n",
      "Filtered out 0 pairs\n",
      "The evaluation results were successfully saved to:\n",
      "- Text format: segmenter_one/evaluation_results.txt\n",
      "Model: segmenter_one\n",
      "Position Scores: Precision=0.949, Recall=0.947, F1=0.948\n",
      "BLEU Score: 0.9561\n",
      "chrF Score: 0.9726\n",
      "Attempting to load from: segmenter_two/model_config.json\n",
      "Using device: cuda\n",
      "Device name: NVIDIA RTX A6000\n",
      "Device memory: 47.535888671875 GB\n",
      "Original shape: (367178, 4)\n",
      "Final shape: (200000, 4)\n",
      "The config file has been saved on segmenter_two\n",
      "Tokenizer path: segmenter_two/tokenizers/tokenizers_tokens.json\n",
      "Loading existing tokenizer from segmenter_two/tokenizers/tokenizers_tokens.json\n",
      "Tokenizer path: segmenter_two/tokenizers/tokenizers_segmenter_two.json\n",
      "Loading existing tokenizer from segmenter_two/tokenizers/tokenizers_segmenter_two.json\n",
      "the dataset length: 200000\n",
      "Max length of source sentence: 30\n",
      "Max length of target sentence: 39\n",
      "Loaded best model from epoch 6\n",
      "Model configuration:\n",
      "- d_model: 256\n",
      "- num_layers: 6\n",
      "- num_heads: 16\n",
      "- d_ff: 1024\n",
      "- dropout: 0.27119126273901606\n",
      "- label_smoothing: 0.014005492657761388\n",
      "- max_grad_norm: 1.1819095309366932\n",
      "- lr: 0.0004197711726342262\n",
      "Loaded best model from epoch 6\n",
      "Model configuration:\n",
      "- d_model: 256\n",
      "- num_layers: 6\n",
      "- num_heads: 16\n",
      "- d_ff: 1024\n",
      "- dropout: 0.27119126273901606\n",
      "- label_smoothing: 0.014005492657761388\n",
      "- max_grad_norm: 1.1819095309366932\n",
      "- lr: 0.0004197711726342262\n",
      "Reading predictions from: segmenter_two/predictions/predictions_20250106_141226.csv\n",
      "Successfully loaded 20000 predictions\n",
      "\n",
      "Example predictions:\n",
      "\n",
      "Example 1:\n",
      "Source: anizukuza\n",
      "Target: a-ni-zuku-z-a\n",
      "Predicted: a-ni-zuku-z-a\n",
      "\n",
      "Example 2:\n",
      "Source: sezinkantolo\n",
      "Target: se-zin-kantolo\n",
      "Predicted: se-zin-kantolo\n",
      "\n",
      "Example 3:\n",
      "Source: ezingathenganga\n",
      "Target: ezi-nga-theng-anga\n",
      "Predicted: ezi-nga-theng-anga\n",
      "Original pairs: 20000\n",
      "Valid pairs after filtering: 20000\n",
      "Filtered out 0 pairs\n",
      "Original pairs: 20000\n",
      "Valid pairs after filtering: 20000\n",
      "Filtered out 0 pairs\n",
      "The evaluation results were successfully saved to:\n",
      "- Text format: segmenter_two/evaluation_results.txt\n",
      "Model: segmenter_two\n",
      "Position Scores: Precision=0.929, Recall=0.930, F1=0.930\n",
      "BLEU Score: 0.9372\n",
      "chrF Score: 0.9626\n",
      "Attempting to load from: segmenter_three/model_config.json\n",
      "Using device: cuda\n",
      "Device name: NVIDIA RTX A6000\n",
      "Device memory: 47.535888671875 GB\n",
      "Original shape: (367178, 4)\n",
      "Final shape: (200000, 4)\n",
      "The config file has been saved on segmenter_three\n",
      "Tokenizer path: segmenter_three/tokenizers/tokenizers_tokens.json\n",
      "Loading existing tokenizer from segmenter_three/tokenizers/tokenizers_tokens.json\n",
      "Tokenizer path: segmenter_three/tokenizers/tokenizers_segmenter_three.json\n",
      "Loading existing tokenizer from segmenter_three/tokenizers/tokenizers_segmenter_three.json\n",
      "the dataset length: 200000\n",
      "Max length of source sentence: 30\n",
      "Max length of target sentence: 36\n",
      "Loaded best model from epoch 48\n",
      "Model configuration:\n",
      "- d_model: 128\n",
      "- num_layers: 4\n",
      "- num_heads: 8\n",
      "- d_ff: 512\n",
      "- dropout: 0.21404304809404834\n",
      "- label_smoothing: 0.0008008147200706972\n",
      "- max_grad_norm: 1.1190287094689317\n",
      "- lr: 0.00031050988283798424\n",
      "Loaded best model from epoch 48\n",
      "Model configuration:\n",
      "- d_model: 128\n",
      "- num_layers: 4\n",
      "- num_heads: 8\n",
      "- d_ff: 512\n",
      "- dropout: 0.21404304809404834\n",
      "- label_smoothing: 0.0008008147200706972\n",
      "- max_grad_norm: 1.1190287094689317\n",
      "- lr: 0.00031050988283798424\n",
      "Reading predictions from: segmenter_three/predictions/predictions_20250106_144200.csv\n",
      "Successfully loaded 20000 predictions\n",
      "\n",
      "Example predictions:\n",
      "\n",
      "Example 1:\n",
      "Source: anizukuza\n",
      "Target: anizuku-z-a\n",
      "Predicted: anizuku-z-a\n",
      "\n",
      "Example 2:\n",
      "Source: sezinkantolo\n",
      "Target: se-zinkantolo\n",
      "Predicted: se-zinkantolo\n",
      "\n",
      "Example 3:\n",
      "Source: ezingathenganga\n",
      "Target: ezinga-theng-anga\n",
      "Predicted: ezinga-theng-anga\n",
      "Original pairs: 20000\n",
      "Valid pairs after filtering: 20000\n",
      "Filtered out 0 pairs\n",
      "Original pairs: 20000\n",
      "Valid pairs after filtering: 20000\n",
      "Filtered out 0 pairs\n",
      "The evaluation results were successfully saved to:\n",
      "- Text format: segmenter_three/evaluation_results.txt\n",
      "Model: segmenter_three\n",
      "Position Scores: Precision=0.929, Recall=0.926, F1=0.928\n",
      "BLEU Score: 0.9326\n",
      "chrF Score: 0.9656\n",
      "\n",
      "Comparison results saved to: model_comparison_results_augmented.csv\n",
      "\n",
      "Comparison Summary:\n",
      "        model_name  position_precision  position_recall  position_f1  \\\n",
      "0    segmenter_one            0.948639         0.946741     0.947689   \n",
      "1    segmenter_two            0.929158         0.930476     0.929817   \n",
      "2  segmenter_three            0.929463         0.925852     0.927654   \n",
      "\n",
      "       bleu      chrf            timestamp  \n",
      "0  0.956071  0.972642  2025-03-24 18:53:20  \n",
      "1  0.937239  0.962614  2025-03-24 18:53:32  \n",
      "2  0.932585  0.965569  2025-03-24 18:53:44  \n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    config_paths = [\n",
    "        \"unaugmented_transformer_models/segmenter_one/model_config.json\",\n",
    "        \"unaugmented_transformer_models/segmenter_two/model_config.json\",\n",
    "        \"unaugmented_transformer_models/segmenter_three/model_config.json\"\n",
    "    ]\n",
    "    comparison_df = save_model_comparison(config_paths)\n",
    "    print(\"\\nComparison Summary:\")\n",
    "    print(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
