{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44ed036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"ray[tune]\" optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98f10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee5cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/python3 -m pip install virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542fe300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install libcudnn8=8.6.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6d72d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 23:53:19.388272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-02 23:53:20.187258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "# Train final model with best parameters\n",
    "from lstm_trainer import SegmentationTrainer\n",
    "from lstm_tuner import LSTMTuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f11b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c776b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting experiment: segmenter_one\n",
      "==================================================\n",
      "\n",
      "Starting experiment for segmenter_one\n",
      "Saving config to: /home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200_finals_100/segmenter_one/config.json\n",
      "Running hyperparameter search for segmenter_one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 23:53:24,748\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-01-02 23:53:25,881\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "2025-01-02 23:53:26,800\tINFO packaging.py:530 -- Creating a file package for local directory '.'.\n",
      "2025-01-02 23:53:27,523\tWARNING packaging.py:405 -- File /home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200/segmenter_three/lstm_model.h5 is very large (25.57MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200/segmenter_three/lstm_model.h5']})`\n",
      "2025-01-02 23:53:27,601\tWARNING packaging.py:405 -- File /home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200/segmenter_one/lstm_model.h5 is very large (25.57MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200/segmenter_one/lstm_model.h5']})`\n",
      "2025-01-02 23:53:27,661\tWARNING packaging.py:405 -- File /home/docker/data/work_projects/Segmentation-Models/lstm_model/models_final_200/segmenter_two/lstm_model.h5 is very large (25.57MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/docker/data/work_projects/Segmentation-Models/lstm_model/models_final_200/segmenter_two/lstm_model.h5']})`\n",
      "2025-01-02 23:53:27,952\tWARNING packaging.py:405 -- File /home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200_finals/segmenter_three/lstm_model.h5 is very large (25.67MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200_finals/segmenter_three/lstm_model.h5']})`\n",
      "2025-01-02 23:53:28,062\tWARNING packaging.py:405 -- File /home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200_finals/segmenter_one/lstm_model.h5 is very large (99.30MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200_finals/segmenter_one/lstm_model.h5']})`\n",
      "2025-01-02 23:53:28,563\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_20acd1d6b8826316.zip' (359.57MiB) to Ray cluster...\n",
      "2025-01-02 23:53:30,223\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_20acd1d6b8826316.zip'.\n",
      "2025-01-02 23:53:31,029\tINFO tune.py:613 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "[I 2025-01-02 23:53:31,044] A new study created in memory with name: optuna\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-01-03 00:26:07</td></tr>\n",
       "<tr><td>Running for: </td><td>00:32:34.56        </td></tr>\n",
       "<tr><td>Memory:      </td><td>55.2/125.7 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 4.000: None | Iter 2.000: None<br>Logical resource usage: 16.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  clip_norm</th><th style=\"text-align: right;\">  decay_rate</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  initial_lr</th><th style=\"text-align: right;\">  label_smoothing</th><th style=\"text-align: right;\">  latent_dim</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_training_function_af5e871b</td><td>TERMINATED</td><td>172.17.0.2:23352</td><td style=\"text-align: right;\">   0.778893</td><td style=\"text-align: right;\">    0.842704</td><td style=\"text-align: right;\">      0.280409</td><td style=\"text-align: right;\"> 6.64147e-05</td><td style=\"text-align: right;\">        0.0834157</td><td style=\"text-align: right;\">        1024</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         208.012</td><td style=\"text-align: right;\">1.21456 </td><td style=\"text-align: right;\">  1.1915  </td><td style=\"text-align: right;\">  0.766591</td></tr>\n",
       "<tr><td>_training_function_02f0a411</td><td>TERMINATED</td><td>172.17.0.2:23785</td><td style=\"text-align: right;\">   1.75058 </td><td style=\"text-align: right;\">    0.848519</td><td style=\"text-align: right;\">      0.111023</td><td style=\"text-align: right;\"> 0.00012672 </td><td style=\"text-align: right;\">        0.0437269</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         202.83 </td><td style=\"text-align: right;\">0.961127</td><td style=\"text-align: right;\">  0.935547</td><td style=\"text-align: right;\">  0.786269</td></tr>\n",
       "<tr><td>_training_function_8bd5d826</td><td>TERMINATED</td><td>172.17.0.2:24197</td><td style=\"text-align: right;\">   1.61315 </td><td style=\"text-align: right;\">    0.814906</td><td style=\"text-align: right;\">      0.299426</td><td style=\"text-align: right;\"> 1.27563e-05</td><td style=\"text-align: right;\">        0.0950836</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         190.817</td><td style=\"text-align: right;\">1.41473 </td><td style=\"text-align: right;\">  1.41812 </td><td style=\"text-align: right;\">  0.708222</td></tr>\n",
       "<tr><td>_training_function_aa464038</td><td>TERMINATED</td><td>172.17.0.2:24607</td><td style=\"text-align: right;\">   1.0588  </td><td style=\"text-align: right;\">    0.942843</td><td style=\"text-align: right;\">      0.140675</td><td style=\"text-align: right;\"> 2.39491e-05</td><td style=\"text-align: right;\">        0.082415 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         189.752</td><td style=\"text-align: right;\">1.3579  </td><td style=\"text-align: right;\">  1.34503 </td><td style=\"text-align: right;\">  0.712234</td></tr>\n",
       "<tr><td>_training_function_31bc40be</td><td>TERMINATED</td><td>172.17.0.2:25016</td><td style=\"text-align: right;\">   0.989628</td><td style=\"text-align: right;\">    0.97643 </td><td style=\"text-align: right;\">      0.220166</td><td style=\"text-align: right;\"> 0.000425512</td><td style=\"text-align: right;\">        0.0610973</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         175.851</td><td style=\"text-align: right;\">0.920938</td><td style=\"text-align: right;\">  0.892096</td><td style=\"text-align: right;\">  0.825157</td></tr>\n",
       "<tr><td>_training_function_35e6e726</td><td>TERMINATED</td><td>172.17.0.2:25424</td><td style=\"text-align: right;\">   0.66116 </td><td style=\"text-align: right;\">    0.973698</td><td style=\"text-align: right;\">      0.124787</td><td style=\"text-align: right;\"> 6.63273e-05</td><td style=\"text-align: right;\">        0.104765 </td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         192.802</td><td style=\"text-align: right;\">1.3465  </td><td style=\"text-align: right;\">  1.34147 </td><td style=\"text-align: right;\">  0.743638</td></tr>\n",
       "<tr><td>_training_function_5e50c16b</td><td>TERMINATED</td><td>172.17.0.2:25834</td><td style=\"text-align: right;\">   1.8712  </td><td style=\"text-align: right;\">    0.815729</td><td style=\"text-align: right;\">      0.119823</td><td style=\"text-align: right;\"> 0.000694709</td><td style=\"text-align: right;\">        0.180517 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         196.617</td><td style=\"text-align: right;\">1.38521 </td><td style=\"text-align: right;\">  1.37069 </td><td style=\"text-align: right;\">  0.850875</td></tr>\n",
       "<tr><td>_training_function_ebe0b694</td><td>TERMINATED</td><td>172.17.0.2:26244</td><td style=\"text-align: right;\">   1.09507 </td><td style=\"text-align: right;\">    0.970566</td><td style=\"text-align: right;\">      0.150576</td><td style=\"text-align: right;\"> 1.69669e-05</td><td style=\"text-align: right;\">        0.104985 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         175.796</td><td style=\"text-align: right;\">1.51653 </td><td style=\"text-align: right;\">  1.50058 </td><td style=\"text-align: right;\">  0.695424</td></tr>\n",
       "<tr><td>_training_function_13614e9a</td><td>TERMINATED</td><td>172.17.0.2:26652</td><td style=\"text-align: right;\">   1.94269 </td><td style=\"text-align: right;\">    0.812057</td><td style=\"text-align: right;\">      0.219448</td><td style=\"text-align: right;\"> 0.000184451</td><td style=\"text-align: right;\">        0.0115617</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         177.813</td><td style=\"text-align: right;\">0.833273</td><td style=\"text-align: right;\">  0.789178</td><td style=\"text-align: right;\">  0.785678</td></tr>\n",
       "<tr><td>_training_function_5b32e0b1</td><td>TERMINATED</td><td>172.17.0.2:27060</td><td style=\"text-align: right;\">   1.53047 </td><td style=\"text-align: right;\">    0.873256</td><td style=\"text-align: right;\">      0.183687</td><td style=\"text-align: right;\"> 2.91957e-05</td><td style=\"text-align: right;\">        0.0952002</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         184.654</td><td style=\"text-align: right;\">1.40373 </td><td style=\"text-align: right;\">  1.39285 </td><td style=\"text-align: right;\">  0.712498</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=23352)\u001b[0m 2025-01-02 23:53:43.095836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=23352)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=23352)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=23352)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=23352)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_accuracy</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_training_function_02f0a411</td><td style=\"text-align: right;\">  0.786269</td><td style=\"text-align: right;\">0.961127</td><td style=\"text-align: right;\">      0.79824 </td><td style=\"text-align: right;\">  0.935547</td></tr>\n",
       "<tr><td>_training_function_13614e9a</td><td style=\"text-align: right;\">  0.785678</td><td style=\"text-align: right;\">0.833273</td><td style=\"text-align: right;\">      0.801685</td><td style=\"text-align: right;\">  0.789178</td></tr>\n",
       "<tr><td>_training_function_31bc40be</td><td style=\"text-align: right;\">  0.825157</td><td style=\"text-align: right;\">0.920938</td><td style=\"text-align: right;\">      0.833579</td><td style=\"text-align: right;\">  0.892096</td></tr>\n",
       "<tr><td>_training_function_35e6e726</td><td style=\"text-align: right;\">  0.743638</td><td style=\"text-align: right;\">1.3465  </td><td style=\"text-align: right;\">      0.750629</td><td style=\"text-align: right;\">  1.34147 </td></tr>\n",
       "<tr><td>_training_function_5b32e0b1</td><td style=\"text-align: right;\">  0.712498</td><td style=\"text-align: right;\">1.40373 </td><td style=\"text-align: right;\">      0.717083</td><td style=\"text-align: right;\">  1.39285 </td></tr>\n",
       "<tr><td>_training_function_5e50c16b</td><td style=\"text-align: right;\">  0.850875</td><td style=\"text-align: right;\">1.38521 </td><td style=\"text-align: right;\">      0.856808</td><td style=\"text-align: right;\">  1.37069 </td></tr>\n",
       "<tr><td>_training_function_8bd5d826</td><td style=\"text-align: right;\">  0.708222</td><td style=\"text-align: right;\">1.41473 </td><td style=\"text-align: right;\">      0.705804</td><td style=\"text-align: right;\">  1.41812 </td></tr>\n",
       "<tr><td>_training_function_aa464038</td><td style=\"text-align: right;\">  0.712234</td><td style=\"text-align: right;\">1.3579  </td><td style=\"text-align: right;\">      0.717418</td><td style=\"text-align: right;\">  1.34503 </td></tr>\n",
       "<tr><td>_training_function_af5e871b</td><td style=\"text-align: right;\">  0.766591</td><td style=\"text-align: right;\">1.21456 </td><td style=\"text-align: right;\">      0.775484</td><td style=\"text-align: right;\">  1.1915  </td></tr>\n",
       "<tr><td>_training_function_ebe0b694</td><td style=\"text-align: right;\">  0.695424</td><td style=\"text-align: right;\">1.51653 </td><td style=\"text-align: right;\">      0.690737</td><td style=\"text-align: right;\">  1.50058 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=23785)\u001b[0m 2025-01-02 23:57:16.394217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=23785)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=23785)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=23785)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=23785)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=24197)\u001b[0m 2025-01-03 00:00:44.384244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=24197)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=24197)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=24197)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=24197)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=24607)\u001b[0m 2025-01-03 00:04:00.401862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=24607)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=24607)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=24607)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=24607)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=25016)\u001b[0m 2025-01-03 00:07:15.450581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=25016)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=25016)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=25016)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=25016)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=25424)\u001b[0m 2025-01-03 00:10:16.440537: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=25424)\u001b[0m Cut-off dataset shape: (40000, 4)\n",
      "\u001b[36m(_training_function pid=25424)\u001b[0m Original dataset shape: (367178, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=25424)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=25424)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=25834)\u001b[0m 2025-01-03 00:13:34.493474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=25834)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=25834)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=25834)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=25834)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=26244)\u001b[0m 2025-01-03 00:16:56.596019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=26244)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=26244)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=26244)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=26244)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=26652)\u001b[0m 2025-01-03 00:19:57.566867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=26652)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=26652)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=26652)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=26652)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(pid=27060)\u001b[0m 2025-01-03 00:23:00.626656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=27060)\u001b[0m Original dataset shape: (367178, 4)\n",
      "\u001b[36m(_training_function pid=27060)\u001b[0m Cut-off dataset shape: (40000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_training_function pid=27060)\u001b[0m WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\u001b[36m(_training_function pid=27060)\u001b[0m WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-03 00:26:07,551\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2025-01-03 00:26:07,556\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/home/docker/data/work_projects/Segmentation-Models/lstm_model/models_200_finals_100/segmenter_one/ray_results/lstm_tune' in 0.0129s.\n",
      "2025-01-03 00:26:07,567\tINFO tune.py:1048 -- Total run time: 1956.54 seconds (1954.54 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best trial config: {'model_name': 'segmenter_one', 'data_path': '/home/docker/data/work_projects/Segmentation-Models/data/valid_linearizations_4.csv', 'save_path': 'models_200_finals_100', 'data_length': 40000, 'label_smoothing': 0.011561664905338498, 'clip_norm': 1.9426870713984559, 'latent_dim': 128, 'batch_size': 64, 'num_epochs': 60, 'train_ratio': 0.8, 'validation_ratio': 0.1, 'test_ratio': 0.1, 'random_seed': 20, 'initial_lr': 0.0001844505568740933, 'decay_steps': 10000, 'decay_rate': 0.8120566806916044, 'dropout_rate': 0.2194481687960585, 'patience': 5, 'validation_split': 0.1, 'tuning_epochs': 5}\n",
      "Best trial final validation loss: 0.7892\n",
      "Best trial final validation accuracy: 0.8017\n",
      "Applying best config and starting training for segmenter_one\n",
      "\n",
      "Training Configuration:\n",
      "\n",
      "Dataset:\n",
      "- Data path: /home/docker/data/work_projects/Segmentation-Models/data/valid_linearizations_4.csv\n",
      "- Dataset size: 200000\n",
      "\n",
      "Model:\n",
      "- Latent dim: 128\n",
      "- Label smoothing: 0.011561664905338498\n",
      "- Gradient clip norm: 1.9426870713984559\n",
      "\n",
      "Training:\n",
      "- Initial learning rate: 0.0001844505568740933\n",
      "- Batch size: 64\n",
      "- Epochs: 60\n",
      "- Dropout rate: 0.2194481687960585\n",
      "- Decay steps: 10000\n",
      "- Decay rate: 0.8120566806916044\n",
      "- Early stopping patience: 5\n",
      "- Validation split: 0.1\n",
      "Original dataset shape: (367178, 4)\n",
      "Cut-off dataset shape: (200000, 4)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 00:26:18.755295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46715 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:e1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "   2/2250 [..............................] - ETA: 2:49 - loss: 3.3032 - accuracy: 0.0389   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 00:26:26.267004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 182s 80ms/step - loss: 0.9895 - accuracy: 0.7414 - val_loss: 0.7565 - val_accuracy: 0.8102\n",
      "Epoch 2/60\n",
      "2250/2250 [==============================] - 176s 78ms/step - loss: 0.6992 - accuracy: 0.8138 - val_loss: 0.6455 - val_accuracy: 0.8261\n",
      "Epoch 3/60\n",
      "2250/2250 [==============================] - 181s 80ms/step - loss: 0.6164 - accuracy: 0.8293 - val_loss: 0.5669 - val_accuracy: 0.8261\n",
      "Epoch 4/60\n",
      "2250/2250 [==============================] - 186s 83ms/step - loss: 0.5523 - accuracy: 0.8315 - val_loss: 0.4981 - val_accuracy: 0.8486\n",
      "Epoch 5/60\n",
      "2250/2250 [==============================] - 214s 95ms/step - loss: 0.4927 - accuracy: 0.8512 - val_loss: 0.4333 - val_accuracy: 0.8703\n",
      "Epoch 6/60\n",
      "2250/2250 [==============================] - 216s 96ms/step - loss: 0.4339 - accuracy: 0.8701 - val_loss: 0.3763 - val_accuracy: 0.8888\n",
      "Epoch 7/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3847 - accuracy: 0.8863 - val_loss: 0.3267 - val_accuracy: 0.9070\n",
      "Epoch 8/60\n",
      "2250/2250 [==============================] - 199s 88ms/step - loss: 0.3430 - accuracy: 0.9001 - val_loss: 0.2874 - val_accuracy: 0.9201\n",
      "Epoch 9/60\n",
      "2250/2250 [==============================] - 195s 87ms/step - loss: 0.3090 - accuracy: 0.9117 - val_loss: 0.2576 - val_accuracy: 0.9311\n",
      "Epoch 10/60\n",
      "2250/2250 [==============================] - 195s 87ms/step - loss: 0.2827 - accuracy: 0.9207 - val_loss: 0.2346 - val_accuracy: 0.9385\n",
      "Epoch 11/60\n",
      "2250/2250 [==============================] - 198s 88ms/step - loss: 0.2621 - accuracy: 0.9278 - val_loss: 0.2171 - val_accuracy: 0.9443\n",
      "Epoch 12/60\n",
      "2250/2250 [==============================] - 199s 88ms/step - loss: 0.2457 - accuracy: 0.9332 - val_loss: 0.2051 - val_accuracy: 0.9481\n",
      "Epoch 13/60\n",
      "2250/2250 [==============================] - 200s 89ms/step - loss: 0.2328 - accuracy: 0.9376 - val_loss: 0.1947 - val_accuracy: 0.9512\n",
      "Epoch 14/60\n",
      "2250/2250 [==============================] - 194s 86ms/step - loss: 0.2223 - accuracy: 0.9410 - val_loss: 0.1861 - val_accuracy: 0.9538\n",
      "Epoch 15/60\n",
      "2250/2250 [==============================] - 198s 88ms/step - loss: 0.2136 - accuracy: 0.9439 - val_loss: 0.1799 - val_accuracy: 0.9558\n",
      "Epoch 16/60\n",
      "2250/2250 [==============================] - 198s 88ms/step - loss: 0.2064 - accuracy: 0.9461 - val_loss: 0.1737 - val_accuracy: 0.9571\n",
      "Epoch 17/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.2004 - accuracy: 0.9481 - val_loss: 0.1685 - val_accuracy: 0.9591\n",
      "Epoch 18/60\n",
      "2250/2250 [==============================] - 199s 88ms/step - loss: 0.1953 - accuracy: 0.9498 - val_loss: 0.1646 - val_accuracy: 0.9597\n",
      "Epoch 19/60\n",
      "2250/2250 [==============================] - 198s 88ms/step - loss: 0.1910 - accuracy: 0.9511 - val_loss: 0.1620 - val_accuracy: 0.9608\n",
      "Epoch 20/60\n",
      "2250/2250 [==============================] - 198s 88ms/step - loss: 0.1873 - accuracy: 0.9523 - val_loss: 0.1596 - val_accuracy: 0.9615\n",
      "Epoch 21/60\n",
      "2250/2250 [==============================] - 195s 87ms/step - loss: 0.1841 - accuracy: 0.9533 - val_loss: 0.1567 - val_accuracy: 0.9623\n",
      "Epoch 22/60\n",
      "2250/2250 [==============================] - 197s 88ms/step - loss: 0.1812 - accuracy: 0.9543 - val_loss: 0.1549 - val_accuracy: 0.9627\n",
      "Epoch 23/60\n",
      "2250/2250 [==============================] - 196s 87ms/step - loss: 0.1795 - accuracy: 0.9550 - val_loss: 0.1527 - val_accuracy: 0.9636\n",
      "Epoch 24/60\n",
      "2250/2250 [==============================] - 192s 85ms/step - loss: 0.1772 - accuracy: 0.9557 - val_loss: 0.1518 - val_accuracy: 0.9638\n",
      "Epoch 25/60\n",
      "2250/2250 [==============================] - 197s 88ms/step - loss: 0.1750 - accuracy: 0.9564 - val_loss: 0.1498 - val_accuracy: 0.9643\n",
      "Epoch 26/60\n",
      "2250/2250 [==============================] - 196s 87ms/step - loss: 0.1731 - accuracy: 0.9570 - val_loss: 0.1484 - val_accuracy: 0.9645\n",
      "Epoch 27/60\n",
      "2250/2250 [==============================] - 196s 87ms/step - loss: 0.1716 - accuracy: 0.9574 - val_loss: 0.1473 - val_accuracy: 0.9649\n",
      "Epoch 28/60\n",
      "2250/2250 [==============================] - 197s 87ms/step - loss: 0.1701 - accuracy: 0.9578 - val_loss: 0.1466 - val_accuracy: 0.9651\n",
      "Epoch 29/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.1687 - accuracy: 0.9583 - val_loss: 0.1453 - val_accuracy: 0.9654\n",
      "Epoch 30/60\n",
      "2250/2250 [==============================] - 189s 84ms/step - loss: 0.1673 - accuracy: 0.9587 - val_loss: 0.1445 - val_accuracy: 0.9658\n",
      "Epoch 31/60\n",
      "2250/2250 [==============================] - 200s 89ms/step - loss: 0.1662 - accuracy: 0.9590 - val_loss: 0.1435 - val_accuracy: 0.9660\n",
      "Epoch 32/60\n",
      "2250/2250 [==============================] - 197s 88ms/step - loss: 0.1652 - accuracy: 0.9594 - val_loss: 0.1429 - val_accuracy: 0.9662\n",
      "Epoch 33/60\n",
      "2250/2250 [==============================] - 195s 87ms/step - loss: 0.1643 - accuracy: 0.9596 - val_loss: 0.1423 - val_accuracy: 0.9663\n",
      "Epoch 34/60\n",
      "2250/2250 [==============================] - 196s 87ms/step - loss: 0.1635 - accuracy: 0.9599 - val_loss: 0.1421 - val_accuracy: 0.9663\n",
      "Epoch 35/60\n",
      "2250/2250 [==============================] - 199s 88ms/step - loss: 0.1626 - accuracy: 0.9602 - val_loss: 0.1412 - val_accuracy: 0.9667\n",
      "Epoch 36/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.1618 - accuracy: 0.9605 - val_loss: 0.1406 - val_accuracy: 0.9668\n",
      "Epoch 37/60\n",
      "2250/2250 [==============================] - 204s 91ms/step - loss: 0.1611 - accuracy: 0.9607 - val_loss: 0.1402 - val_accuracy: 0.9670\n",
      "Epoch 38/60\n",
      "2250/2250 [==============================] - 198s 88ms/step - loss: 0.1604 - accuracy: 0.9608 - val_loss: 0.1398 - val_accuracy: 0.9670\n",
      "Epoch 39/60\n",
      "2250/2250 [==============================] - 190s 84ms/step - loss: 0.1598 - accuracy: 0.9611 - val_loss: 0.1392 - val_accuracy: 0.9672\n",
      "Epoch 40/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.1593 - accuracy: 0.9612 - val_loss: 0.1390 - val_accuracy: 0.9674\n",
      "Epoch 41/60\n",
      "2250/2250 [==============================] - 199s 89ms/step - loss: 0.1588 - accuracy: 0.9614 - val_loss: 0.1387 - val_accuracy: 0.9674\n",
      "Epoch 42/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.1583 - accuracy: 0.9614 - val_loss: 0.1381 - val_accuracy: 0.9675\n",
      "Epoch 43/60\n",
      "2250/2250 [==============================] - 203s 90ms/step - loss: 0.1577 - accuracy: 0.9617 - val_loss: 0.1379 - val_accuracy: 0.9676\n",
      "Epoch 44/60\n",
      "2250/2250 [==============================] - 190s 85ms/step - loss: 0.1573 - accuracy: 0.9618 - val_loss: 0.1377 - val_accuracy: 0.9676\n",
      "Epoch 45/60\n",
      "2250/2250 [==============================] - 189s 84ms/step - loss: 0.1570 - accuracy: 0.9619 - val_loss: 0.1375 - val_accuracy: 0.9676\n",
      "Epoch 46/60\n",
      "2250/2250 [==============================] - 194s 86ms/step - loss: 0.1566 - accuracy: 0.9621 - val_loss: 0.1369 - val_accuracy: 0.9678\n",
      "Epoch 47/60\n",
      "2250/2250 [==============================] - 198s 88ms/step - loss: 0.1560 - accuracy: 0.9622 - val_loss: 0.1365 - val_accuracy: 0.9679\n",
      "Epoch 49/60\n",
      "1502/2250 [===================>..........] - ETA: 1:02 - loss: 0.1556 - accuracy: 0.9624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 197s 88ms/step - loss: 0.1578 - accuracy: 0.9655 - val_loss: 0.1449 - val_accuracy: 0.9689\n",
      "Epoch 20/60\n",
      "1134/2250 [==============>...............] - ETA: 1:31 - loss: 0.1557 - accuracy: 0.9661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.1340 - accuracy: 0.9715 - val_loss: 0.1293 - val_accuracy: 0.9722\n",
      "Epoch 47/60\n",
      " 544/2250 [======>.......................] - ETA: 2:29 - loss: 0.1340 - accuracy: 0.9715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2250 [============================>.] - ETA: 5s - loss: 0.1334 - accuracy: 0.9717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2250 [==============================] - 210s 93ms/step - loss: 0.3719 - accuracy: 0.9611 - val_loss: 0.3558 - val_accuracy: 0.9652\n",
      "Epoch 12/60\n",
      "2250/2250 [==============================] - 212s 94ms/step - loss: 0.3635 - accuracy: 0.9633 - val_loss: 0.3502 - val_accuracy: 0.9663\n",
      "Epoch 13/60\n",
      "2250/2250 [==============================] - 205s 91ms/step - loss: 0.3578 - accuracy: 0.9647 - val_loss: 0.3466 - val_accuracy: 0.9668\n",
      "Epoch 14/60\n",
      "2250/2250 [==============================] - 207s 92ms/step - loss: 0.3533 - accuracy: 0.9656 - val_loss: 0.3436 - val_accuracy: 0.9674\n",
      "Epoch 15/60\n",
      "2250/2250 [==============================] - 211s 94ms/step - loss: 0.3493 - accuracy: 0.9665 - val_loss: 0.3394 - val_accuracy: 0.9682\n",
      "Epoch 16/60\n",
      "2250/2250 [==============================] - 206s 92ms/step - loss: 0.3460 - accuracy: 0.9672 - val_loss: 0.3384 - val_accuracy: 0.9683\n",
      "Epoch 17/60\n",
      "2250/2250 [==============================] - 210s 94ms/step - loss: 0.3430 - accuracy: 0.9678 - val_loss: 0.3368 - val_accuracy: 0.9685\n",
      "Epoch 18/60\n",
      "2250/2250 [==============================] - 208s 92ms/step - loss: 0.3422 - accuracy: 0.9686 - val_loss: 0.3368 - val_accuracy: 0.9685\n",
      "Epoch 19/60\n",
      "2250/2250 [==============================] - 208s 93ms/step - loss: 0.3400 - accuracy: 0.9768 - val_loss: 0.3339 - val_accuracy: 0.9954\n",
      "Epoch 20/60\n",
      "2250/2250 [==============================] - 207s 92ms/step - loss: 0.3382 - accuracy: 0.9945 - val_loss: 0.3321 - val_accuracy: 0.9957\n",
      "Epoch 21/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3367 - accuracy: 0.9953 - val_loss: 0.3316 - val_accuracy: 0.9957\n",
      "Epoch 22/60\n",
      "2250/2250 [==============================] - 200s 89ms/step - loss: 0.3369 - accuracy: 0.9951 - val_loss: 0.3324 - val_accuracy: 0.9955\n",
      "Epoch 23/60\n",
      "2250/2250 [==============================] - 203s 90ms/step - loss: 0.3345 - accuracy: 0.9957 - val_loss: 0.3300 - val_accuracy: 0.9960\n",
      "Epoch 24/60\n",
      "2250/2250 [==============================] - 203s 90ms/step - loss: 0.3334 - accuracy: 0.9959 - val_loss: 0.3297 - val_accuracy: 0.9959\n",
      "Epoch 25/60\n",
      "2250/2250 [==============================] - 204s 91ms/step - loss: 0.3328 - accuracy: 0.9960 - val_loss: 0.3289 - val_accuracy: 0.9961\n",
      "Epoch 26/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3322 - accuracy: 0.9961 - val_loss: 0.3290 - val_accuracy: 0.9961\n",
      "Epoch 27/60\n",
      "2250/2250 [==============================] - 199s 89ms/step - loss: 0.3316 - accuracy: 0.9962 - val_loss: 0.3281 - val_accuracy: 0.9962\n",
      "Epoch 28/60\n",
      "2250/2250 [==============================] - 200s 89ms/step - loss: 0.3301 - accuracy: 0.9965 - val_loss: 0.3277 - val_accuracy: 0.9963\n",
      "Epoch 29/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3296 - accuracy: 0.9966 - val_loss: 0.3271 - val_accuracy: 0.9964\n",
      "Epoch 30/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3289 - accuracy: 0.9967 - val_loss: 0.3271 - val_accuracy: 0.9963\n",
      "Epoch 31/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3284 - accuracy: 0.9968 - val_loss: 0.3263 - val_accuracy: 0.9965\n",
      "Epoch 32/60\n",
      "2250/2250 [==============================] - 201s 90ms/step - loss: 0.3282 - accuracy: 0.9968 - val_loss: 0.3260 - val_accuracy: 0.9965\n",
      "Epoch 33/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3274 - accuracy: 0.9970 - val_loss: 0.3254 - val_accuracy: 0.9966\n",
      "Epoch 34/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3270 - accuracy: 0.9971 - val_loss: 0.3255 - val_accuracy: 0.9966\n",
      "Epoch 35/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3266 - accuracy: 0.9972 - val_loss: 0.3254 - val_accuracy: 0.9965\n",
      "Epoch 36/60\n",
      "2250/2250 [==============================] - 201s 90ms/step - loss: 0.3261 - accuracy: 0.9973 - val_loss: 0.3249 - val_accuracy: 0.9967\n",
      "Epoch 37/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3262 - accuracy: 0.9972 - val_loss: 0.3249 - val_accuracy: 0.9967\n",
      "Epoch 38/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3252 - accuracy: 0.9975 - val_loss: 0.3248 - val_accuracy: 0.9967\n",
      "Epoch 39/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3250 - accuracy: 0.9975 - val_loss: 0.3244 - val_accuracy: 0.9968\n",
      "Epoch 40/60\n",
      "2250/2250 [==============================] - 203s 90ms/step - loss: 0.3249 - accuracy: 0.9975 - val_loss: 0.3244 - val_accuracy: 0.9967\n",
      "Epoch 41/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3247 - accuracy: 0.9976 - val_loss: 0.3242 - val_accuracy: 0.9968\n",
      "Epoch 42/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3245 - accuracy: 0.9976 - val_loss: 0.3243 - val_accuracy: 0.9968\n",
      "Epoch 43/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3240 - accuracy: 0.9977 - val_loss: 0.3239 - val_accuracy: 0.9968\n",
      "Epoch 44/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3237 - accuracy: 0.9977 - val_loss: 0.3242 - val_accuracy: 0.9968\n",
      "Epoch 45/60\n",
      "2250/2250 [==============================] - 201s 89ms/step - loss: 0.3236 - accuracy: 0.9978 - val_loss: 0.3235 - val_accuracy: 0.9969\n",
      "Epoch 46/60\n",
      "2250/2250 [==============================] - 202s 90ms/step - loss: 0.3232 - accuracy: 0.9979 - val_loss: 0.3234 - val_accuracy: 0.9969\n",
      "Epoch 47/60\n",
      "2250/2250 [==============================] - 203s 90ms/step - loss: 0.3230 - accuracy: 0.9979 - val_loss: 0.3234 - val_accuracy: 0.9969\n",
      "Epoch 48/60\n",
      "2250/2250 [==============================] - 200s 89ms/step - loss: 0.3227 - accuracy: 0.9980 - val_loss: 0.3232 - val_accuracy: 0.9970\n",
      "Epoch 49/60\n",
      "1705/2250 [=====================>........] - ETA: 46s - loss: 0.3225 - accuracy: 0.9980"
     ]
    }
   ],
   "source": [
    "# Function to run a complete experiment\n",
    "def run_experiment(config_name, data_length_tune=40000, data_length_train=200000):\n",
    "    config = {\n",
    "        \"model_name\": config_name,\n",
    "        \"data_path\": \"/home/docker/data/work_projects/Segmentation-Models/data/valid_linearizations_4.csv\",\n",
    "        \"save_path\": \"models_200_finals_100\",\n",
    "        \"data_length\": data_length_tune, \n",
    "        \"label_smoothing\": 0.1, \n",
    "        \"clip_norm\": 1.0,\n",
    "        \"latent_dim\": 256,\n",
    "        \"batch_size\": 64,\n",
    "        \"num_epochs\": 60,\n",
    "        \"train_ratio\": 0.8,\n",
    "        \"validation_ratio\": 0.1,\n",
    "        \"test_ratio\": 0.1,\n",
    "        \"random_seed\": 20,\n",
    "        \"initial_lr\": 0.00001,\n",
    "        \"decay_steps\": 10000,\n",
    "        \"decay_rate\": 0.9,\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"patience\": 5,\n",
    "        \"validation_split\": 0.1\n",
    "    }\n",
    "    \n",
    "    # Setup directories\n",
    "    save_dir = os.path.join(os.getcwd(), config[\"save_path\"], config[\"model_name\"])\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    config_path = os.path.join(save_dir, \"config.json\")\n",
    "    print(f\"\\nStarting experiment for {config_name}\")\n",
    "    print(f\"Saving config to: {config_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Save initial config\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "            \n",
    "        # Run hyperparameter search\n",
    "        print(f\"Running hyperparameter search for {config_name}\")\n",
    "        tuner = LSTMTuner(config)\n",
    "        best_config, analysis = tuner.run_hyperparameter_search(\n",
    "            num_samples=10,\n",
    "            num_epochs=5\n",
    "        )\n",
    "        \n",
    "        # Update config with best parameters\n",
    "        print(f\"Applying best config and starting training for {config_name}\")\n",
    "        final_config = tuner.apply_best_config(best_config)\n",
    "        final_config[\"data_length\"] = data_length_train  # Full dataset for training\n",
    "        final_config[\"batch_size\"] = 64\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(final_config, f, indent=2)\n",
    "        \n",
    "        # Train final model\n",
    "        trainer = SegmentationTrainer(config_path)\n",
    "        model, data_processor = trainer.train()\n",
    "        \n",
    "        # Clear GPU memory\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"Completed experiment for {config_name}\")\n",
    "        return model, data_processor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in experiment {config_name}: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Cleanup\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "# Run experiments sequentially\n",
    "experiments = [\"segmenter_one\", \"segmenter_two\", \"segmenter_three\"]\n",
    "\n",
    "for exp_name in experiments:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Starting experiment: {exp_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    model, data_processor = run_experiment(exp_name)\n",
    "    \n",
    "    # Force cleanup between experiments\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"\\nCompleted experiment: {exp_name}\")\n",
    "    print(f\"{'='*50}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
