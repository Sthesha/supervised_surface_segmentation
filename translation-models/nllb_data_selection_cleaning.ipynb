{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b4e8b9-aaf7-4714-ae89-658825f15299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
      "  Installing build dependencies ... \u001bdone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.2 (from fasttext)\n",
      "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /root/miniconda3/envs/ml/lib/python3.10/site-packages (from fasttext) (72.1.0)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/ml/lib/python3.10/site-packages (from fasttext) (1.24.1)\n",
      "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (pydone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=325277 sha256=fdd7b339ff58ecf4ecef5c066af2a2977d73ffe3ca737e67032348ccbdc2a777\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677faea2-8f88-48f1-b5b5-57267a9a532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zul_Latn'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import fasttext\n",
    "import re\n",
    "import csv\n",
    "\n",
    "model = fasttext.load_model('lid201-model.bin')\n",
    "lang_prediction = model.predict(\"mina ngithanda inyama\")\n",
    "lang_label = lang_prediction[0][0].split(\"__label__\")[1]\n",
    "lang_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fbd7014-579c-4aeb-a8b9-8b5ed9dc0a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1000, Accepted: 863, Unique Zulu: 863\n",
      "Processed: 2000, Accepted: 1740, Unique Zulu: 1740\n",
      "Processed: 3000, Accepted: 2631, Unique Zulu: 2631\n",
      "Processed: 4000, Accepted: 3507, Unique Zulu: 3507\n",
      "Processed: 5000, Accepted: 4408, Unique Zulu: 4408\n",
      "Processed: 6000, Accepted: 5310, Unique Zulu: 5310\n",
      "Processed: 7000, Accepted: 6204, Unique Zulu: 6204\n",
      "Processed: 8000, Accepted: 7109, Unique Zulu: 7109\n",
      "Processed: 9000, Accepted: 8003, Unique Zulu: 8003\n",
      "Processed: 10000, Accepted: 8889, Unique Zulu: 8889\n",
      "Processed: 11000, Accepted: 9773, Unique Zulu: 9773\n",
      "Processed: 12000, Accepted: 10664, Unique Zulu: 10664\n",
      "Processed: 13000, Accepted: 11561, Unique Zulu: 11561\n",
      "Processed: 14000, Accepted: 12456, Unique Zulu: 12456\n",
      "Processed: 15000, Accepted: 13356, Unique Zulu: 13356\n",
      "Processed: 16000, Accepted: 14265, Unique Zulu: 14265\n",
      "Processed: 17000, Accepted: 15140, Unique Zulu: 15140\n",
      "Processed: 18000, Accepted: 16027, Unique Zulu: 16027\n",
      "Processed: 19000, Accepted: 16910, Unique Zulu: 16910\n",
      "Processed: 20000, Accepted: 17786, Unique Zulu: 17786\n",
      "Processed: 21000, Accepted: 18666, Unique Zulu: 18666\n",
      "Processed: 22000, Accepted: 19559, Unique Zulu: 19559\n",
      "Processed: 23000, Accepted: 20426, Unique Zulu: 20426\n",
      "Processed: 24000, Accepted: 21306, Unique Zulu: 21306\n",
      "Processed: 25000, Accepted: 22178, Unique Zulu: 22178\n",
      "Processed: 26000, Accepted: 23064, Unique Zulu: 23064\n",
      "Processed: 27000, Accepted: 23948, Unique Zulu: 23948\n",
      "Processed: 28000, Accepted: 24816, Unique Zulu: 24816\n",
      "Processed: 29000, Accepted: 25710, Unique Zulu: 25710\n",
      "Processed: 30000, Accepted: 26574, Unique Zulu: 26574\n",
      "Processed: 31000, Accepted: 27445, Unique Zulu: 27445\n",
      "Processed: 32000, Accepted: 28300, Unique Zulu: 28300\n",
      "Processed: 33000, Accepted: 29145, Unique Zulu: 29145\n",
      "Processed: 34000, Accepted: 30016, Unique Zulu: 30016\n",
      "Processed: 35000, Accepted: 30895, Unique Zulu: 30895\n",
      "Processed: 36000, Accepted: 31738, Unique Zulu: 31738\n",
      "Processed: 37000, Accepted: 32611, Unique Zulu: 32611\n",
      "Processed: 38000, Accepted: 33482, Unique Zulu: 33482\n",
      "Processed: 39000, Accepted: 34330, Unique Zulu: 34330\n",
      "Processed: 40000, Accepted: 35184, Unique Zulu: 35184\n",
      "Processed: 41000, Accepted: 36036, Unique Zulu: 36036\n",
      "Processed: 42000, Accepted: 36901, Unique Zulu: 36901\n",
      "Processed: 43000, Accepted: 37760, Unique Zulu: 37760\n",
      "Processed: 44000, Accepted: 38628, Unique Zulu: 38628\n",
      "Processed: 45000, Accepted: 39499, Unique Zulu: 39499\n",
      "Processed: 46000, Accepted: 40374, Unique Zulu: 40374\n",
      "Processed: 47000, Accepted: 41212, Unique Zulu: 41212\n",
      "Processed: 48000, Accepted: 42065, Unique Zulu: 42065\n",
      "Processed: 49000, Accepted: 42937, Unique Zulu: 42937\n",
      "Processed: 50000, Accepted: 43773, Unique Zulu: 43773\n",
      "Processed: 51000, Accepted: 44618, Unique Zulu: 44618\n",
      "Processed: 52000, Accepted: 45457, Unique Zulu: 45457\n",
      "Processed: 53000, Accepted: 46293, Unique Zulu: 46293\n",
      "Processed: 54000, Accepted: 47132, Unique Zulu: 47132\n",
      "Processed: 55000, Accepted: 47986, Unique Zulu: 47986\n",
      "Processed: 56000, Accepted: 48829, Unique Zulu: 48829\n",
      "Processed: 57000, Accepted: 49665, Unique Zulu: 49665\n",
      "Processed: 58000, Accepted: 50497, Unique Zulu: 50497\n",
      "Processed: 59000, Accepted: 51335, Unique Zulu: 51335\n",
      "Processed: 60000, Accepted: 52187, Unique Zulu: 52187\n",
      "Processed: 61000, Accepted: 53019, Unique Zulu: 53019\n",
      "Processed: 62000, Accepted: 53867, Unique Zulu: 53867\n",
      "Processed: 63000, Accepted: 54720, Unique Zulu: 54720\n",
      "Processed: 64000, Accepted: 55557, Unique Zulu: 55557\n",
      "Processed: 65000, Accepted: 56391, Unique Zulu: 56391\n",
      "Processed: 66000, Accepted: 57235, Unique Zulu: 57235\n",
      "Processed: 67000, Accepted: 58068, Unique Zulu: 58068\n",
      "Processed: 68000, Accepted: 58906, Unique Zulu: 58906\n",
      "Processed: 69000, Accepted: 59743, Unique Zulu: 59743\n",
      "Processed: 70000, Accepted: 60578, Unique Zulu: 60578\n",
      "Processed: 71000, Accepted: 61411, Unique Zulu: 61411\n",
      "Processed: 72000, Accepted: 62244, Unique Zulu: 62244\n",
      "Processed: 73000, Accepted: 63065, Unique Zulu: 63065\n",
      "Processed: 74000, Accepted: 63885, Unique Zulu: 63885\n",
      "Processed: 75000, Accepted: 64707, Unique Zulu: 64707\n",
      "Processed: 76000, Accepted: 65515, Unique Zulu: 65515\n",
      "Processed: 77000, Accepted: 66348, Unique Zulu: 66348\n",
      "Processed: 78000, Accepted: 67169, Unique Zulu: 67169\n",
      "Processed: 79000, Accepted: 67977, Unique Zulu: 67977\n",
      "Processed: 80000, Accepted: 68796, Unique Zulu: 68796\n",
      "Processed: 81000, Accepted: 69604, Unique Zulu: 69604\n",
      "Processed: 82000, Accepted: 70434, Unique Zulu: 70434\n",
      "Processed: 83000, Accepted: 71268, Unique Zulu: 71268\n",
      "Processed: 84000, Accepted: 72074, Unique Zulu: 72074\n",
      "Processed: 85000, Accepted: 72892, Unique Zulu: 72892\n",
      "Processed: 86000, Accepted: 73705, Unique Zulu: 73705\n",
      "Processed: 87000, Accepted: 74528, Unique Zulu: 74528\n",
      "Processed: 88000, Accepted: 75340, Unique Zulu: 75340\n",
      "Processed: 89000, Accepted: 76153, Unique Zulu: 76153\n",
      "Processed: 90000, Accepted: 76973, Unique Zulu: 76973\n",
      "Processed: 91000, Accepted: 77797, Unique Zulu: 77797\n",
      "Processed: 92000, Accepted: 78617, Unique Zulu: 78617\n",
      "Processed: 93000, Accepted: 79412, Unique Zulu: 79412\n",
      "Processed: 94000, Accepted: 80235, Unique Zulu: 80235\n",
      "Processed: 95000, Accepted: 81017, Unique Zulu: 81017\n",
      "Processed: 96000, Accepted: 81832, Unique Zulu: 81832\n",
      "Processed: 97000, Accepted: 82641, Unique Zulu: 82641\n",
      "Processed: 98000, Accepted: 83447, Unique Zulu: 83447\n",
      "Processed: 99000, Accepted: 84225, Unique Zulu: 84225\n",
      "Processed: 100000, Accepted: 85024, Unique Zulu: 85024\n",
      "Processed: 101000, Accepted: 85834, Unique Zulu: 85834\n",
      "Processed: 102000, Accepted: 86647, Unique Zulu: 86647\n",
      "Processed: 103000, Accepted: 87439, Unique Zulu: 87439\n",
      "Processed: 104000, Accepted: 88223, Unique Zulu: 88223\n",
      "Processed: 105000, Accepted: 89042, Unique Zulu: 89042\n",
      "Processed: 106000, Accepted: 89855, Unique Zulu: 89855\n",
      "Processed: 107000, Accepted: 90657, Unique Zulu: 90657\n",
      "Processed: 108000, Accepted: 91460, Unique Zulu: 91460\n",
      "Processed: 109000, Accepted: 92256, Unique Zulu: 92256\n",
      "Processed: 110000, Accepted: 93041, Unique Zulu: 93041\n",
      "Processed: 111000, Accepted: 93825, Unique Zulu: 93825\n",
      "Processed: 112000, Accepted: 94614, Unique Zulu: 94614\n",
      "Processed: 113000, Accepted: 95407, Unique Zulu: 95407\n",
      "Processed: 114000, Accepted: 96200, Unique Zulu: 96200\n",
      "Processed: 115000, Accepted: 96982, Unique Zulu: 96982\n",
      "Processed: 116000, Accepted: 97787, Unique Zulu: 97787\n",
      "Processed: 117000, Accepted: 98584, Unique Zulu: 98584\n",
      "Processed: 118000, Accepted: 99346, Unique Zulu: 99346\n",
      "\n",
      "Final Results:\n",
      "Total pairs processed: 118799\n",
      "Accepted pairs: 100000\n",
      "Rejected pairs: 18799\n",
      "\n",
      "Results saved to:\n",
      "- Accepted pairs: accepted_pairs.csv\n",
      "- Rejected pairs: rejected_pairs.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import fasttext\n",
    "import re\n",
    "import csv\n",
    "\n",
    "model = fasttext.load_model('lid201-model.bin')\n",
    "\n",
    "def is_zulu_xhosa_swati(line):\n",
    "    lang_prediction = model.predict(line)\n",
    "    lang_label = lang_prediction[0][0].split(\"__label__\")[1]\n",
    "    if lang_label in ['zul_Latn']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_english(line):\n",
    "    lang_prediction = model.predict(line)\n",
    "    lang_label = lang_prediction[0][0].split(\"__label__\")[1]\n",
    "    if lang_label in ['eng_Latn']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filter_parallel_text(input_file, accepted_file, rejected_file, model, target_accepted=100000):\n",
    "    accepted_pairs = []\n",
    "    rejected_pairs = []\n",
    "    total_processed = 0\n",
    "    unique_zulu = set()  # Track unique Zulu sentences\n",
    "    \n",
    "    while len(accepted_pairs) < target_accepted:\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            header = next(reader)  # Skip header\n",
    "            \n",
    "            for row in enumerate(reader):\n",
    "                # Skip rows we've already processed in previous iterations\n",
    "                if row[0] < total_processed:\n",
    "                    continue\n",
    "                    \n",
    "                if len(row[1]) != 2:\n",
    "                    continue\n",
    "                    \n",
    "                eng_text, zulu_text = row[1]\n",
    "                \n",
    "                # Check if both texts pass their respective language tests\n",
    "                valid_eng = is_english(eng_text)\n",
    "                valid_zulu = is_zulu_xhosa_swati(zulu_text)\n",
    "                is_unique_zulu = zulu_text not in unique_zulu\n",
    "                \n",
    "                # Store the pair and the reason for rejection if any\n",
    "                if valid_eng and valid_zulu and is_unique_zulu:\n",
    "                    accepted_pairs.append((eng_text, zulu_text))\n",
    "                    unique_zulu.add(zulu_text)  # Add to set of unique Zulu sentences\n",
    "                    if len(accepted_pairs) >= target_accepted:\n",
    "                        break\n",
    "                else:\n",
    "                    reason = []\n",
    "                    if not valid_eng:\n",
    "                        reason.append(\"Failed English check\")\n",
    "                    if not valid_zulu:\n",
    "                        reason.append(\"Failed Zulu/Xhosa/Swati check\")\n",
    "                    if not is_unique_zulu:\n",
    "                        reason.append(\"Duplicate Zulu sentence\")\n",
    "                    rejected_pairs.append({\n",
    "                        \"english\": eng_text,\n",
    "                        \"zulu\": zulu_text,\n",
    "                        \"reason\": \" & \".join(reason)\n",
    "                    })\n",
    "                \n",
    "                total_processed += 1\n",
    "                \n",
    "                # Print progress periodically\n",
    "                if total_processed % 1000 == 0:\n",
    "                    print(f\"Processed: {total_processed}, Accepted: {len(accepted_pairs)}, Unique Zulu: {len(unique_zulu)}\")\n",
    "        \n",
    "        # If we've processed all rows but still haven't found enough accepted pairs\n",
    "        if total_processed == sum(1 for row in csv.reader(open(input_file))) - 1:\n",
    "            print(\"Reached end of file before finding enough accepted pairs.\")\n",
    "            break\n",
    "    \n",
    "    # Write accepted pairs to CSV\n",
    "    with open(accepted_file, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(['english', 'zulu'])\n",
    "        writer.writerows(accepted_pairs)\n",
    "    \n",
    "    # Write rejected pairs to JSON for better readability of rejection reasons\n",
    "    with open(rejected_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(rejected_pairs, outfile, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return accepted_pairs, rejected_pairs\n",
    "\n",
    "# Usage\n",
    "input_file = 'eng_zul_nllb_data.csv'\n",
    "accepted_file = 'accepted_pairs.csv'\n",
    "rejected_file = 'rejected_pairs.json'\n",
    "\n",
    "accepted, rejected = filter_parallel_text(input_file, accepted_file, rejected_file, model)\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Total pairs processed: {len(accepted) + len(rejected)}\")\n",
    "print(f\"Accepted pairs: {len(accepted)}\")\n",
    "print(f\"Rejected pairs: {len(rejected)}\")\n",
    "print(f\"\\nResults saved to:\")\n",
    "print(f\"- Accepted pairs: {accepted_file}\")\n",
    "print(f\"- Rejected pairs: {rejected_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff083172-ff3c-4d90-b0a1-15709b594be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Cleaned text saved to 'cleaned_flores_zulu_val.txt'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "with open(\"flores_zulu_val.txt\", \"r\") as file:\n",
    "    sentences = file.readlines()[:100]\n",
    "\n",
    "cleaned_sentences = [preprocess_text(sentence.strip()) for sentence in sentences]\n",
    "\n",
    "with open(\"cleaned_flores_zulu_val.txt\", \"w\") as file:\n",
    "    for sentence in cleaned_sentences:\n",
    "        file.write(sentence + \"\\n\")\n",
    "\n",
    "print(\"Preprocessing complete. Cleaned text saved to 'cleaned_flores_zulu_val.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea033ed-b28e-47cc-be7d-a37442220e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>isizulu</th>\n",
       "      <th>segmenter_one</th>\n",
       "      <th>segmenter_two</th>\n",
       "      <th>segmenter_three</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>it is important to take the time to listen and...</td>\n",
       "      <td>kubalulekile ukuthatha isikhathi sokulalela fu...</td>\n",
       "      <td>ku-balulek-ile uku-thath-a i-si-khathi so-ku-l...</td>\n",
       "      <td>ku-balulek-ile uku-thath-a isi-khathi so-ku-la...</td>\n",
       "      <td>ku-balulek-ile uku-thath-a isikhathi so-ku-lal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>do you know a resource thats not on our list</td>\n",
       "      <td>uyalazi uhlelo oluhle olungekho ohlwini lwethu</td>\n",
       "      <td>u-ya-l-azi u-hlelo olu-hl-e olu-nge-kho o-hl-w...</td>\n",
       "      <td>u-ya-l-azi u-hlelo olu-hl-e olu-nge-kho o-hlwi...</td>\n",
       "      <td>uya-l-azi uhlelo oluhl-e olungekho o-hlwini lw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>the local bank is obviously not likely to take...</td>\n",
       "      <td>ibhange lakho lendawo ngokusobala ngeke likhip...</td>\n",
       "      <td>i-bhang-e la-kho le-ndawo ng-o-ku-sobal-a ng-e...</td>\n",
       "      <td>i-bhang-e la-kho le-n-dawo ngo-ku-sobal-a ngek...</td>\n",
       "      <td>ibhange la-kho le-ndawo ngo-ku-sobal-a ngek-e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>ambulances were waiting</td>\n",
       "      <td>ambulanciers lalinde</td>\n",
       "      <td>a-m-bulanci-ers l-a-lind-e</td>\n",
       "      <td>a-m-bulancires lali-nde</td>\n",
       "      <td>ambulanci-ers lalind-e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>i am proud that speed humps will be erected he...</td>\n",
       "      <td>kuyangojabulisa ukuthi sekuzokwakhiwa izinciph...</td>\n",
       "      <td>ku-ya-ng-ojabulis-a uku-thi se-ku-zo-kw-akhiw-...</td>\n",
       "      <td>ku-ya-ng-ojabulis-a uku-thi se-ku-zokw-akhiw-a...</td>\n",
       "      <td>kuya-ng-ojabulis-a uku-thi sekuzokw-akhiw-a iz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 english  \\\n",
       "99995  it is important to take the time to listen and...   \n",
       "99996       do you know a resource thats not on our list   \n",
       "99997  the local bank is obviously not likely to take...   \n",
       "99998                            ambulances were waiting   \n",
       "99999  i am proud that speed humps will be erected he...   \n",
       "\n",
       "                                                 isizulu  \\\n",
       "99995  kubalulekile ukuthatha isikhathi sokulalela fu...   \n",
       "99996     uyalazi uhlelo oluhle olungekho ohlwini lwethu   \n",
       "99997  ibhange lakho lendawo ngokusobala ngeke likhip...   \n",
       "99998                               ambulanciers lalinde   \n",
       "99999  kuyangojabulisa ukuthi sekuzokwakhiwa izinciph...   \n",
       "\n",
       "                                           segmenter_one  \\\n",
       "99995  ku-balulek-ile uku-thath-a i-si-khathi so-ku-l...   \n",
       "99996  u-ya-l-azi u-hlelo olu-hl-e olu-nge-kho o-hl-w...   \n",
       "99997  i-bhang-e la-kho le-ndawo ng-o-ku-sobal-a ng-e...   \n",
       "99998                         a-m-bulanci-ers l-a-lind-e   \n",
       "99999  ku-ya-ng-ojabulis-a uku-thi se-ku-zo-kw-akhiw-...   \n",
       "\n",
       "                                           segmenter_two  \\\n",
       "99995  ku-balulek-ile uku-thath-a isi-khathi so-ku-la...   \n",
       "99996  u-ya-l-azi u-hlelo olu-hl-e olu-nge-kho o-hlwi...   \n",
       "99997  i-bhang-e la-kho le-n-dawo ngo-ku-sobal-a ngek...   \n",
       "99998                            a-m-bulancires lali-nde   \n",
       "99999  ku-ya-ng-ojabulis-a uku-thi se-ku-zokw-akhiw-a...   \n",
       "\n",
       "                                         segmenter_three  \n",
       "99995  ku-balulek-ile uku-thath-a isikhathi so-ku-lal...  \n",
       "99996  uya-l-azi uhlelo oluhl-e olungekho o-hlwini lw...  \n",
       "99997  ibhange la-kho le-ndawo ngo-ku-sobal-a ngek-e ...  \n",
       "99998                             ambulanci-ers lalind-e  \n",
       "99999  kuya-ng-ojabulis-a uku-thi sekuzokw-akhiw-a iz...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the first CSV with English and Zulu\n",
    "df1 = pd.read_csv('./final_merged_data_nllb.csv')\n",
    "df2 = pd.read_csv('./final_merged_data_nllb_two.csv')\n",
    "df3 = pd.read_csv('./final_merged_data_nllb_three.csv')\n",
    "\n",
    "# # Read the second CSV with original and segmented Zulu\n",
    "# df2 = pd.read_csv('segmentation_results_segmenter_three.csv')\n",
    "\n",
    "# Create new dataframe with desired columns\n",
    "final_df = pd.DataFrame({\n",
    "    'english': df1['english'],\n",
    "    'isizulu': df1['isizulu'],\n",
    "    'segmenter_one': df1['segmenter_one'],\n",
    "    'segmenter_two': df2['segmenter_two'],\n",
    "    'segmenter_three': df3['segmenter_three']\n",
    "})\n",
    "\n",
    "final_df.to_csv('nllb_segmented_data.csv', index=False)\n",
    "\n",
    "final_df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0aae0f-d88f-42df-9967-47c592e15851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random sample row:\n",
      "--------------------------------------------------------------------------------\n",
      "English: it was devoted entirely to opening the eyes of those blinded by the doctrines of evolution and creationism\n",
      "isiZulu: uma wasebenzisa ctrlshiftf khonake ctrle kuyodingeka ukuthi ziqalise futhi\n",
      "Segmented isiZulu: uma wa-sebenzis-a ctrlshif-f khonak-e ctrl-e kuyo-dingek-a uku-thi zi-qalis-e futh-i\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_row = final_df.sample(n=1)\n",
    "\n",
    "# Print the row in a nicely formatted way\n",
    "print(\"\\nRandom sample row:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"English: {random_row['english'].values[0]}\")\n",
    "print(f\"isiZulu: {random_row['isizulu'].values[0]}\")\n",
    "print(f\"Segmented isiZulu: {random_row['segmented_isizulu'].values[0]}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "469db511-4b6e-4b9f-ab8d-76dcd0694f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row at index 99998\n",
      "--------------------------------------------------------------------------------\n",
      "English: ambulances were waiting\n",
      "isiZulu: ambulanciers lalinde\n",
      "Segmented isiZulu: ambulanci-ers lalind-e\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "index = 99998  # Change this to any index you want\n",
    "row = final_df.iloc[index]\n",
    "\n",
    "print(\"\\nRow at index\", index)\n",
    "print(\"-\" * 80)\n",
    "print(f\"English: {row['english']}\")\n",
    "print(f\"isiZulu: {row['isizulu']}\")\n",
    "print(f\"Segmented isiZulu: {row['segmented_isizulu']}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a00f6-7cf4-4183-ab12-dd67aaa86920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
